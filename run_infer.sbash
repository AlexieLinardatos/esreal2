#!/bin/bash
#SBATCH --job-name=esreal_infer
#SBATCH --account=def-fqureshi
#SBATCH --gres=gpu:1
#SBATCH --cpus-per-task=4
#SBATCH --mem=32G
#SBATCH --time=02:00:00
#SBATCH --output=%x-%j.out



set -e

#########################
# CONFIG - EDIT IF NEEDED
#########################

# GitHub repo with your ESREAL2 code
REPO_URL="https://github.com/AlexieLinardatos/ESREAL2.git"
REPO_NAME="ESREAL2"

# Hugging Face dataset repo (COCO / ESREAL dataset)
HF_DATASET_URL="https://huggingface.co/datasets/AlexieLinardatos/esreal-dataset"

# Hugging Face weights repo (GroundingDINO + SDXL etc.)
HF_WEIGHTS_URL="https://huggingface.co/AlexieLinardatos/myDino"

# LAVIS / ESREAL conda env name
ENV_NAME="lavis"

# Lavis dataset builder name used by infer.py and train.py
# ðŸ‘‰ CHANGE THIS to whatever your custom builder is called
DATASET_NAME="esreal_dataset"    # placeholder

# Prompt used in infer.py for BLIP2
# (you can also pass this in from the command line instead)
INFER_PROMPT="Describe this image in detail."

# PPO / training hyperparams (tweak as you like)
BATCH_SIZE=4
CHUNK_SIZE=4
LR=1e-5
SEQ_LENGTH=256
MAX_NEW_TOKENS=64
REPETITION_PENALTY=1.2
INIT_KL_COEF=0.05
ALPHA=1.0
IS_REC_PENALTY=true
TASK_NAME="short_caption"
EXPERIMENT_NAME="esreal_run1"

#########################
# 1) Modules + Conda
#########################

module load python/3.10 2>/dev/null || true
module load git-lfs       2>/dev/null || true
git lfs install || true

source ~/miniconda3/etc/profile.d/conda.sh

#########################
# 2) Get / update code
#########################

CODE_DIR="$SCRATCH/$REPO_NAME"

if [ ! -d "$CODE_DIR" ]; then
    echo "[INFO] Cloning ESREAL2 into $CODE_DIR"
    git clone "$REPO_URL" "$CODE_DIR"
else
    echo "[INFO] Updating ESREAL2 in $CODE_DIR"
    cd "$CODE_DIR"
    git pull
fi

cd "$CODE_DIR"

#########################
# 3) Conda environment
#########################

if ! conda env list | grep -q " ${ENV_NAME} "; then
    echo "[INFO] Creating conda env '${ENV_NAME}' from environment_lavis.yml"
    conda env create -n "${ENV_NAME}" -f environment_lavis.yml
fi

echo "[INFO] Activating env '${ENV_NAME}'"
conda activate "${ENV_NAME}"

#########################
# 4) Hugging Face auth
#########################

# These must be set in your environment before sbatch:
#   export HF_DATASET_TOKEN=...
#   export HF_WEIGHTS_TOKEN=...
: "${HF_DATASET_TOKEN:?HF_DATASET_TOKEN is not set}"
: "${HF_WEIGHTS_TOKEN:?HF_WEIGHTS_TOKEN is not set}"

git config --global credential.helper store

cat <<EOF > ~/.git-credentials
https://$HF_DATASET_TOKEN:@huggingface.co
https://$HF_WEIGHTS_TOKEN:@huggingface.co
EOF

# This is what gdino_registry.py expects
export HF_TOKEN="$HF_WEIGHTS_TOKEN"

#########################
# 5) Download dataset
#########################

DATASET_DIR="$CODE_DIR/dataset"

if [ ! -d "$DATASET_DIR" ]; then
    echo "[INFO] Cloning dataset from Hugging Face into $DATASET_DIR"
    git lfs clone "$HF_DATASET_URL" "$DATASET_DIR"
fi

# Adjust these to match how your HF dataset is laid out
DF_PATH="$DATASET_DIR/esreal_data.csv"   # or images.csv / whatever you use
IMAGE_DIR="$DATASET_DIR"                 # or "$DATASET_DIR/data/coco/..." etc.

#########################
# 6) Download weights
#########################

WEIGHTS_DIR="$CODE_DIR/weights"

if [ ! -d "$WEIGHTS_DIR" ]; then
    echo "[INFO] Cloning weights from Hugging Face into $WEIGHTS_DIR"
    git lfs clone "$HF_WEIGHTS_URL" "$WEIGHTS_DIR"
fi

# Some parts of your code may still look at this
export ESREAL_WEIGHTS="$WEIGHTS_DIR"

#########################
# 7) Output + state
#########################

OUT_DIR="$SCRATCH/esreal_outputs"
mkdir -p "$OUT_DIR"

STATE_PATH="$OUT_DIR/state.json"
CAPTIONS_JSONL="$OUT_DIR/blip2_flant5xl.jsonl"

#########################
# 8) Run infer.py (image -> text)
#########################

TARGET_CKPT=""   # leave empty if youâ€™re using the base BLIP2 weights

echo "[INFO] Starting infer.py ..."

python infer.py \
  --target_checkpoint "$TARGET_CKPT" \
  --save_dir "$OUT_DIR" \
  --save_filename "$(basename "$CAPTIONS_JSONL")" \
  --start_index 0 \
  --interval 10000000 \
  --dataset_name "$DATASET_NAME" \
  --df_path "$DF_PATH" \
  --image_dir "$IMAGE_DIR" \
  --prompt "$INFER_PROMPT" \
  --batch_size "$BATCH_SIZE" \
  --num_workers 4 \
  --state_path "$STATE_PATH" \
  --save_every 500

echo "[INFO] Inference finished."
echo "[INFO] Captions written to: $CAPTIONS_JSONL"

#########################
# 9) Run train.py (PPO + local reward)
#########################

CHECKPOINT_DIR="$OUT_DIR/checkpoints"

echo "[INFO] Starting train.py (PPO)..."

python train.py \
  --model_path "Salesforce/blip2-flan-t5-xl" \
  --dataset_name "$DATASET_NAME" \
  --df_path "$DF_PATH" \
  --image_dir "$IMAGE_DIR" \
  --task_name "$TASK_NAME" \
  --batch_size "$BATCH_SIZE" \
  --chunk_size "$CHUNK_SIZE" \
  --lr "$LR" \
  --seq_length "$SEQ_LENGTH" \
  --max_new_tokens "$MAX_NEW_TOKENS" \
  --repetition_penalty "$REPETITION_PENALTY" \
  --init_kl_coef "$INIT_KL_COEF" \
  --alpha "$ALPHA" \
  --is_rec_penalty "$IS_REC_PENALTY" \
  --checkpoint_dir "$CHECKPOINT_DIR" \
  --experiment_name "$EXPERIMENT_NAME" \
  --resume_from_checkpoint ""

echo "[INFO] Training finished."
echo "[INFO] Checkpoints in: $CHECKPOINT_DIR"